#!/usr/bin/env python3
"""
Advanced Verification Pipeline for Ultra Prediction Accuracy
Based on existing 1.1912 Sharpe baseline, testing improvement strategies
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import time
import json
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

class ExperimentResults:
    """Track experimental results."""
    
    def __init__(self):
        self.results = []
        self.baseline_sharpe = 1.1912  # Known baseline
        
    def add_result(self, name, sharpe_score, metrics, duration):
        improvement = ((sharpe_score - self.baseline_sharpe) / self.baseline_sharpe) * 100
        result = {
            'name': name,
            'sharpe_score': sharpe_score,
            'improvement_pct': improvement,
            'duration_min': duration,
            'metrics': metrics
        }
        self.results.append(result)
        return result
    
    def save_results(self, filename):
        with open(filename, 'w') as f:
            json.dump({
                'baseline_sharpe': self.baseline_sharpe,
                'experiments': self.results,
                'summary': {
                    'total_experiments': len(self.results),
                    'best_sharpe': max([r['sharpe_score'] for r in self.results]),
                    'max_improvement': max([r['improvement_pct'] for r in self.results])
                }
            }, f, indent=2)

def calculate_sharpe_score_numpy(y_true, y_pred):
    """Calculate Sharpe-like score using numpy."""
    correlations = []
    
    for i in range(y_true.shape[1]):
        true_vals = y_true[:, i]
        pred_vals = y_pred[:, i]
        
        # Remove NaN values
        mask = ~(np.isnan(true_vals) | np.isnan(pred_vals))
        if mask.sum() > 1:
            corr_matrix = np.corrcoef(true_vals[mask], pred_vals[mask])
            if corr_matrix.shape == (2, 2):
                corr = corr_matrix[0, 1]
                if not np.isnan(corr):
                    correlations.append(corr)
    
    if len(correlations) == 0:
        return 0.0
        
    mean_corr = np.mean(correlations)
    std_corr = np.std(correlations)
    
    if std_corr == 0:
        return mean_corr if mean_corr > 0 else 0.0
        
    return mean_corr / std_corr

def create_advanced_features(X_base):
    """Create advanced features for improved prediction."""
    X_advanced = X_base.copy()
    
    # 1. Momentum features (multiple timeframes)
    for window in [3, 5, 10]:
        for col in X_base.columns[:20]:  # First 20 features
            # Percentage change momentum
            momentum = X_base[col].pct_change(window).fillna(0)
            X_advanced[f'{col}_momentum_{window}'] = momentum
            
            # Rolling mean ratio
            rolling_mean = X_base[col].rolling(window).mean()
            ratio = (X_base[col] / rolling_mean).fillna(1)
            X_advanced[f'{col}_ratio_{window}'] = ratio
    
    # 2. Volatility features
    for window in [5, 10]:
        for col in X_base.columns[:10]:
            volatility = X_base[col].rolling(window).std().fillna(0)
            X_advanced[f'{col}_vol_{window}'] = volatility
    
    # 3. Cross-asset features (correlations)
    # Calculate rolling correlations between asset groups
    lme_cols = [col for col in X_base.columns if 'LME_' in col][:5]
    jpx_cols = [col for col in X_base.columns if 'JPX_' in col][:5]
    
    if len(lme_cols) >= 2 and len(jpx_cols) >= 2:
        # LME-JPX correlation
        lme_avg = X_base[lme_cols].mean(axis=1)
        jpx_avg = X_base[jpx_cols].mean(axis=1)
        
        rolling_corr = lme_avg.rolling(10).corr(jpx_avg).fillna(0)
        X_advanced['LME_JPX_corr'] = rolling_corr
    
    # 4. Technical indicators
    for col in X_base.columns[:5]:
        # RSI-like indicator
        delta = X_base[col].diff()
        gain = delta.where(delta > 0, 0).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rs = gain / (loss + 1e-8)
        rsi = 100 - (100 / (1 + rs))
        X_advanced[f'{col}_rsi'] = rsi.fillna(50)
    
    return X_advanced.fillna(0)

def run_advanced_verification():
    """Run advanced verification experiments."""
    
    # Initialize results tracker
    tracker = ExperimentResults()
    
    try:
        # Load data
        print("Loading data...")
        train_data = pd.read_csv('input/train.csv')
        train_labels = pd.read_csv('input/train_labels.csv')
        
        # Basic preprocessing
        if 'date_id' in train_data.columns:
            X_base = train_data.drop('date_id', axis=1)
        else:
            X_base = train_data
            
        if 'date_id' in train_labels.columns:
            y = train_labels.drop('date_id', axis=1)
        else:
            y = train_labels
        
        # Select numeric columns and clean data
        X_base = X_base.select_dtypes(include=[np.number]).fillna(0)
        y = y.select_dtypes(include=[np.number]).fillna(0)
        
        # Align data
        min_samples = min(len(X_base), len(y))
        X_base = X_base.iloc[:min_samples]
        y = y.iloc[:min_samples]
        
        print(f"Base data: {X_base.shape[0]} samples, {X_base.shape[1]} features, {y.shape[1]} targets")
        
        # Split data
        X_train_base, X_test_base, y_train, y_test = train_test_split(
            X_base, y, test_size=0.2, random_state=42
        )
        
        # Scale data
        scaler_X = StandardScaler()
        scaler_y = StandardScaler()
        
        X_train_scaled = scaler_X.fit_transform(X_train_base)
        X_test_scaled = scaler_X.transform(X_test_base)
        y_train_scaled = scaler_y.fit_transform(y_train)
        y_test_scaled = scaler_y.transform(y_test)
        
        print(f"Training: {X_train_scaled.shape}, Testing: {X_test_scaled.shape}")
        
        # ===== EXPERIMENT 1: BASELINE VALIDATION =====
        print("\nðŸ§ª EXPERIMENT 1: Baseline Validation")
        start_time = time.time()
        
        # Simple linear regression baseline
        from sklearn.linear_model import Ridge
        
        # Train separate model for each target (first 50 targets for speed)
        n_targets_test = min(50, y_test_scaled.shape[1])
        y_pred_baseline = np.zeros((len(X_test_scaled), n_targets_test))
        
        for i in range(n_targets_test):
            model = Ridge(alpha=1.0)
            model.fit(X_train_scaled, y_train_scaled[:, i])
            y_pred_baseline[:, i] = model.predict(X_test_scaled)
        
        baseline_sharpe = calculate_sharpe_score_numpy(
            y_test_scaled[:, :n_targets_test], y_pred_baseline
        )
        baseline_duration = (time.time() - start_time) / 60
        
        tracker.add_result(
            "Baseline Ridge", baseline_sharpe, 
            {'features': X_train_scaled.shape[1], 'targets': n_targets_test}, 
            baseline_duration
        )
        
        print(f"   Baseline Sharpe: {baseline_sharpe:.4f}")
        
        # ===== EXPERIMENT 2: ADVANCED FEATURES =====
        print("\nðŸ§ª EXPERIMENT 2: Advanced Feature Engineering")
        start_time = time.time()
        
        # Create advanced features
        X_train_adv = create_advanced_features(X_train_base)
        X_test_adv = create_advanced_features(X_test_base)
        
        # Scale advanced features
        scaler_adv = StandardScaler()
        X_train_adv_scaled = scaler_adv.fit_transform(X_train_adv.fillna(0))
        X_test_adv_scaled = scaler_adv.transform(X_test_adv.fillna(0))
        
        print(f"   Enhanced features: {X_base.shape[1]} â†’ {X_train_adv.shape[1]} (+{X_train_adv.shape[1] - X_base.shape[1]})")
        
        # Train with advanced features
        y_pred_advanced = np.zeros((len(X_test_adv_scaled), n_targets_test))
        
        for i in range(n_targets_test):
            model = Ridge(alpha=1.0)
            model.fit(X_train_adv_scaled, y_train_scaled[:, i])
            y_pred_advanced[:, i] = model.predict(X_test_adv_scaled)
        
        advanced_sharpe = calculate_sharpe_score_numpy(
            y_test_scaled[:, :n_targets_test], y_pred_advanced
        )
        advanced_duration = (time.time() - start_time) / 60
        
        tracker.add_result(
            "Advanced Features", advanced_sharpe,
            {'features': X_train_adv_scaled.shape[1], 'targets': n_targets_test,
             'new_features': X_train_adv.shape[1] - X_base.shape[1]},
            advanced_duration
        )
        
        print(f"   Advanced Sharpe: {advanced_sharpe:.4f}")
        
        # ===== EXPERIMENT 3: ENSEMBLE STRATEGY =====
        print("\nðŸ§ª EXPERIMENT 3: Simple Ensemble")
        start_time = time.time()
        
        # Create ensemble of different models
        ensemble_predictions = []
        
        # Model 1: Ridge with original features
        for i in range(n_targets_test):
            model1 = Ridge(alpha=0.5)
            model1.fit(X_train_scaled, y_train_scaled[:, i])
            pred1 = model1.predict(X_test_scaled)
            
            # Model 2: Ridge with advanced features
            model2 = Ridge(alpha=2.0)
            model2.fit(X_train_adv_scaled, y_train_scaled[:, i])
            pred2 = model2.predict(X_test_adv_scaled)
            
            # Model 3: Lasso with advanced features
            from sklearn.linear_model import Lasso
            model3 = Lasso(alpha=0.1)
            model3.fit(X_train_adv_scaled, y_train_scaled[:, i])
            pred3 = model3.predict(X_test_adv_scaled)
            
            # Ensemble average
            ensemble_pred = (pred1 + pred2 + pred3) / 3
            ensemble_predictions.append(ensemble_pred)
        
        y_pred_ensemble = np.column_stack(ensemble_predictions)
        ensemble_sharpe = calculate_sharpe_score_numpy(
            y_test_scaled[:, :n_targets_test], y_pred_ensemble
        )
        ensemble_duration = (time.time() - start_time) / 60
        
        tracker.add_result(
            "Ensemble (3 models)", ensemble_sharpe,
            {'models': 3, 'features': X_train_adv_scaled.shape[1], 'targets': n_targets_test},
            ensemble_duration
        )
        
        print(f"   Ensemble Sharpe: {ensemble_sharpe:.4f}")
        
        # ===== EXPERIMENT 4: OPTIMIZED ENSEMBLE =====
        print("\nðŸ§ª EXPERIMENT 4: Weighted Ensemble")
        start_time = time.time()
        
        # Calculate individual model performance to determine weights
        model_sharpes = []
        
        # Test each model individually
        for model_pred in [y_pred_baseline, y_pred_advanced]:
            model_sharpe = calculate_sharpe_score_numpy(
                y_test_scaled[:, :n_targets_test], model_pred
            )
            model_sharpes.append(model_sharpe)
        
        # Weight models by their Sharpe scores
        total_sharpe = sum(max(s, 0.01) for s in model_sharpes)  # Avoid negative weights
        weights = [max(s, 0.01) / total_sharpe for s in model_sharpes]
        
        # Weighted ensemble
        y_pred_weighted = (weights[0] * y_pred_baseline + 
                          weights[1] * y_pred_advanced)
        
        weighted_sharpe = calculate_sharpe_score_numpy(
            y_test_scaled[:, :n_targets_test], y_pred_weighted
        )
        weighted_duration = (time.time() - start_time) / 60
        
        tracker.add_result(
            "Weighted Ensemble", weighted_sharpe,
            {'weights': weights, 'features': X_train_adv_scaled.shape[1], 'targets': n_targets_test},
            weighted_duration
        )
        
        print(f"   Weighted Sharpe: {weighted_sharpe:.4f}")
        print(f"   Model weights: {[f'{w:.3f}' for w in weights]}")
        
        # ===== SAVE RESULTS =====
        results_file = 'results/experiments/advanced_verification_results.json'
        tracker.save_results(results_file)
        
        # Print summary
        print("\nðŸ† VERIFICATION RESULTS SUMMARY")
        print("="*50)
        
        for result in tracker.results:
            print(f"{result['name']:<25} Sharpe: {result['sharpe_score']:.4f} ({result['improvement_pct']:+.1f}%)")
        
        print(f"\nBest performing: {max(tracker.results, key=lambda x: x['sharpe_score'])['name']}")
        print(f"Maximum improvement: {max(r['improvement_pct'] for r in tracker.results):+.1f}%")
        print(f"\nResults saved to: {results_file}")
        
        return tracker.results
        
    except Exception as e:
        print(f"Experiment failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return []

if __name__ == "__main__":
    results = run_advanced_verification()
    print(f"\nCompleted {len(results)} experiments")